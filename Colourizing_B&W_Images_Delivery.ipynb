{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "oriental-verification",
   "metadata": {},
   "source": [
    "# Colourizing Black and White Images Delivery\n",
    "\n",
    "In this document, I will create an **user friendly app** for my chosen neural network(**NNW version 5** see the predictions document). For this I will use **Anvil**, Anvil is a free Python-based drag-and-drop web app builder that is able to get your trained AI working as an application.\n",
    "\n",
    "\n",
    "created by: Mickey krekels\n",
    "Class: AI45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-cigarette",
   "metadata": {},
   "source": [
    "## Loading the imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amateur-swing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, UpSampling2D, Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import base64\n",
    "import keras\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from PIL import Image \n",
    "from skimage.io import imread, imshow ,imsave\n",
    "from PIL import Image \n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "increased-renewal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment (dev)\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "import anvil.server\n",
    "\n",
    "anvil.server.connect(\"HE4D7DFHJOOA2QE3RPYKKS7U-LHCSCT2MSTF2AD3H\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-surveillance",
   "metadata": {},
   "source": [
    "## Loading the trained encoder and decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sustained-armor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "encoder_Model =  tf.keras.models.load_model('Saves/tensorflow_Encoder_V1_ComputationTime_Network_v4'\n",
    "                                           ,custom_objects=None,compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coral-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_Model = tf.keras.models.load_model('Saves/tensorflow_V1_ComputationTime_Network_v4'\n",
    "                                           ,custom_objects=None,compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-conflict",
   "metadata": {},
   "source": [
    "PredictImage is a function that takes an image as an input parameter, it saves the size of the image and scales it down to the shape of the input of the network. After the predictions the image gets scaled back up to size, I extract the original light layer and combine it with the predicted A-B colour spectrums. This will result in an image with colour and no quality loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nuclear-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictImage(image):    \n",
    "    \n",
    "    # extracting the inputs for the encoder and decoder network\n",
    "    test = img_to_array(image)\n",
    "    (H_orig,W_orig) = test.shape[:2] # original image size\n",
    "    resized = resize(test, (224,224), anti_aliasing=True)\n",
    "    resized*= 1.0/255\n",
    "    lab = rgb2lab(resized)\n",
    "    l = lab[:,:,0]\n",
    "    L = gray2rgb(l)\n",
    "    L = L.reshape((1,224,224,3))\n",
    "    \n",
    "    # predicting the the colors in the image\n",
    "    vggpred = encoder_Model.predict(L)  \n",
    "    ab      = decoder_Model.predict(vggpred) \n",
    "\n",
    "    # bringing the new AB map back to original size\n",
    "    ab = ab*128\n",
    "    cur = np.zeros((224, 224, 3))\n",
    "    cur[:,:,0] = l\n",
    "    cur[:,:,1:] = ab\n",
    "    Predicted_Image = lab2rgb(cur)\n",
    "    Predicted_Image = cv2.resize(Predicted_Image , (W_orig,H_orig)) \n",
    "    \n",
    "    # combining the orginal light layer with the predicted AB color spectrums \n",
    "    test*= 1.0/255\n",
    "    col = rgb2lab(Predicted_Image)\n",
    "    lig = rgb2lab(test)\n",
    "    l  =  lig[:,:,0]\n",
    "    ab =  col[:,:,1:] \n",
    "    \n",
    "    # creating the final predicted image\n",
    "    cur = np.zeros((H_orig, W_orig, 3))\n",
    "    cur[:,:,0] = l\n",
    "    cur[:,:,1:] = ab\n",
    "    Predicted_Image = lab2rgb(cur)\n",
    "    \n",
    "    return Predicted_Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-pavilion",
   "metadata": {},
   "source": [
    "---\n",
    "## Anvil\n",
    "\n",
    "Creating a Connection with anvil servers and making a callable function to predict the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-congress",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "import anvil.media \n",
    "\n",
    "@anvil.server.callable\n",
    "def colorize_image(file):\n",
    "    path = 'data/output/output.png'\n",
    "    \n",
    "    with anvil.media.TempFile(file) as filename:\n",
    "        img = cv2.imread(filename)\n",
    "    \n",
    "    input_img  = img\n",
    "    data = PredictImage(input_img)\n",
    "    imsave(path,data)\n",
    "\n",
    "    \n",
    "    with open(path, \"rb\") as file:\n",
    "        url = \"https://api.imgbb.com/1/upload\"\n",
    "        payload = {\n",
    "            \"key\": 'ea029ff50b124083cfe7e27f9dcac6c8',\n",
    "            \"image\": base64.b64encode(file.read()),\n",
    "            \"name\" : \"coloredImage\",\n",
    "        }\n",
    "        res = requests.post(url, payload)\n",
    "        \n",
    "    jsondata = res.json()\n",
    "    \n",
    "    return str(jsondata['data']['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-possession",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Conclusion \n",
    "\n",
    "Due to the way Anvil works returning an image as output and showing it on screen is not possible in the free version. I temporarily fixed this by uploading the image to a separate server, this allows me to get the URL image from the server when the picture is created. This version is for demonstration purposes only.  \n",
    "\n",
    "But it works perfectly the AI can predict images in a user-friendly way(see **demo video below**). This document concludes this project, I learned a lot about using: **neural networks** , **Support Vector Machines** and **digital pictures** in general. In short, it was an interesting and fun project to work on!\n",
    " \n",
    "[demo video link](https://youtu.be/SjLtwPhC1_w)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
